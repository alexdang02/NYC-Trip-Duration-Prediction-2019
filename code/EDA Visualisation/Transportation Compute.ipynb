{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "root_folder = \"/home/trungdc/unimelb/MAST30024/asm/mast30034_2021_s2_project_1-alexdang02-1\"\n",
    "data_dir = os.path.join(root_folder, \"Data\")\n",
    "SQLOutput_dir = os.path.join(root_folder, \"code/SparkSQL_Output\")\n",
    "plot_dir = os.path.join(root_folder, \"Plots\")\n",
    "resource_save = os.path.join(root_folder,\"code\", \"EDA Visualisation\", \"stat\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', True)\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "fhvcompany = [\"HV0002\", \"HV0003\", \"HV0004\", \"HV0005\"]\n",
    "juno = \"B02914 B02907 B02907 B02907\".split(\" \")\n",
    "lyft = \"B02510 B02510\".split(\" \") \n",
    "uber = \"B02877 B02866 B02882 B02869 B02617 B02876 B02865 B02512 B02888 B02864 B02883 B02875 B02682 B02880 B02870 B02404 B02598 B02765 B02879 B02867 B02878 B02887 B02872 B02836 B02884 B02835 B02764 B02889 B02871 B02395 B03136 B02800\".split(\" \")\n",
    "base_numbers = []\n",
    "base_numbers = juno + lyft + uber"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def convert_base_to_company(Dispatching_base_number):\n",
    "    if Dispatching_base_number in lyft:\n",
    "        return \"lyft\"\n",
    "    elif Dispatching_base_number in juno:\n",
    "        return \"juno\"\n",
    "    else:\n",
    "        return \"uber\"\n",
    "udfconvert_base_to_company = udf(convert_base_to_company, StringType())\n",
    "\n",
    "def convert_license_to_company(hvfhs_license_num):\n",
    "    if hvfhs_license_num == \"HV0002\":\n",
    "        return \"juno\"\n",
    "    elif hvfhs_license_num == \"HV0003\":\n",
    "        return \"uber\"\n",
    "    elif hvfhs_license_num == \"HV0004\":\n",
    "        return \"via\"\n",
    "    else:\n",
    "        return \"lyft\"\n",
    "udfconvert_license_to_company = udf(convert_license_to_company, StringType())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# fvfhv data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2018 data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "fhv2018_count = []\n",
    "month = 1\n",
    "year = 2018\n",
    "for file in sorted(os.listdir(os.path.join(data_dir,\"Trip\",\"fhvhv\", \"2018\"))):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_dir,\"Trip\",\"fhvhv\", \"2018\", file)\n",
    "        fhv2018 = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(file_path) \n",
    "        fhv2018 = fhv2018.filter(fhv2018.Dispatching_base_number.isin(base_numbers)) \\\n",
    "        .withColumn(\"Company\", udfconvert_base_to_company(fhv2018.Dispatching_base_number)) \n",
    "        fhv2018.createOrReplaceTempView(\"fhv2018\")\n",
    "        SQL = \"\"\"\n",
    "        SELECT Company, COUNT(*) AS Frequency\n",
    "        FROM fhv2018\n",
    "        GROUP BY Company\n",
    "        \"\"\"\n",
    "        output = spark.sql(SQL).toPandas()\n",
    "        output[\"Month\"] = [month] * len(output.index)\n",
    "        output[\"Year\"] = [year] * len(output.index)\n",
    "        print(output)\n",
    "        output.to_pickle(os.path.join(resource_save, \"Company\",f\"{month}-{year}.pkl\" ))\n",
    "        count = fhv2018.count()\n",
    "        print(f\"File {file} has {count} rows\")\n",
    "        fhv2018_count.append(count)\n",
    "        month += 1\n",
    "pd.DataFrame(fhv2018_count).to_pickle(os.path.join(resource_save, \"fhv2018.pkl\"))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3141012      1  2018\n",
      "1    juno    1378191      1  2018\n",
      "2    uber   12688559      1  2018\n",
      "File fhv_tripdata_2018-01.csv has 17207762 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3144050      2  2018\n",
      "1    juno    1329836      2  2018\n",
      "2    uber   12434761      2  2018\n",
      "File fhv_tripdata_2018-02.csv has 16908647 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3471602      3  2018\n",
      "1    juno    1402393      3  2018\n",
      "2    uber   14489383      3  2018\n",
      "File fhv_tripdata_2018-03.csv has 19363378 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3332985      4  2018\n",
      "1    juno     999872      4  2018\n",
      "2    uber   14225839      4  2018\n",
      "File fhv_tripdata_2018-04.csv has 18558696 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3400356      5  2018\n",
      "1    juno    1244326      5  2018\n",
      "2    uber   14591260      5  2018\n",
      "File fhv_tripdata_2018-05.csv has 19235942 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3664808      6  2018\n",
      "1    juno    1101655      6  2018\n",
      "2    uber   14012101      6  2018\n",
      "File fhv_tripdata_2018-06.csv has 18778564 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3632375      7  2018\n",
      "1    juno    1018602      7  2018\n",
      "2    uber   14915946      7  2018\n",
      "File fhv_tripdata_2018-07.csv has 19566923 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3936418      8  2018\n",
      "1    juno    1032199      8  2018\n",
      "2    uber   14939835      8  2018\n",
      "File fhv_tripdata_2018-08.csv has 19908452 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3960252      9  2018\n",
      "1    juno    1029481      9  2018\n",
      "2    uber   14990675      9  2018\n",
      "File fhv_tripdata_2018-09.csv has 19980408 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    4246575     10  2018\n",
      "1    juno    1104745     10  2018\n",
      "2    uber   15736427     10  2018\n",
      "File fhv_tripdata_2018-10.csv has 21087747 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    4195596     11  2018\n",
      "1    juno    1048668     11  2018\n",
      "2    uber   15510957     11  2018\n",
      "File fhv_tripdata_2018-11.csv has 20755221 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    4697772     12  2018\n",
      "1    juno     860436     12  2018\n",
      "2    uber   15913104     12  2018\n",
      "File fhv_tripdata_2018-12.csv has 21471312 rows\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2019 data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "fhv2019_count = []\n",
    "month = 1\n",
    "year = 2019\n",
    "for file in sorted(os.listdir(os.path.join(data_dir,\"Trip\",\"fhvhv\", \"2019\"))):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_dir,\"Trip\",\"fhvhv\", \"2019\", file)\n",
    "        fhv2019 = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(file_path) \n",
    "        if file == \"fhv_tripdata_2019-01.csv\":\n",
    "            fhv2019 = fhv2019.filter(fhv2019.dispatching_base_num.isin(base_numbers)) \\\n",
    "            .withColumn(\"Company\", udfconvert_base_to_company(fhv2019.dispatching_base_num)) \n",
    "        else:\n",
    "            fhv2019 = fhv2019.withColumn(\"Company\", udfconvert_license_to_company(fhv2019.hvfhs_license_num))\n",
    "        fhv2019.createOrReplaceTempView(\"fhv2019\")\n",
    "        SQL = \"\"\"\n",
    "        SELECT Company, COUNT(*) AS Frequency\n",
    "        FROM fhv2019\n",
    "        GROUP BY Company\n",
    "        \"\"\"\n",
    "        output = spark.sql(SQL).toPandas()\n",
    "        output[\"Month\"] = [month] * len(output.index)\n",
    "        output[\"Year\"] = [year] * len(output.index)\n",
    "        print(output)\n",
    "        output.to_pickle(os.path.join(resource_save, \"Company\",f\"{month}-{year}.pkl\" ))\n",
    "        count = fhv2019.count()\n",
    "        print(f\"File {file} has {count} rows\")\n",
    "        fhv2019_count.append(count)\n",
    "        month += 1\n",
    "pd.DataFrame(fhv2019_count).to_pickle(os.path.join(resource_save, \"fhv2019.pkl\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Company  Frequency  Month  Year\n",
      "0    lyft    4623412      1  2019\n",
      "1    juno     733671      1  2019\n",
      "2    uber   15332400      1  2019\n",
      "File fhv_tripdata_2019-01.csv has 20689483 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    4690916      2  2019\n",
      "1    juno     979266      2  2019\n",
      "2    uber   13504994      2  2019\n",
      "3     via     983926      2  2019\n",
      "File fhvhv_tripdata_2019-02.csv has 20159102 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    4699040      3  2019\n",
      "1    juno     835215      3  2019\n",
      "2    uber   17248340      3  2019\n",
      "3     via    1082003      3  2019\n",
      "File fhvhv_tripdata_2019-03.csv has 23864598 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    4290694      4  2019\n",
      "1    juno     740532      4  2019\n",
      "2    uber   15657399      4  2019\n",
      "3     via    1046142      4  2019\n",
      "File fhvhv_tripdata_2019-04.csv has 21734767 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    4681802      5  2019\n",
      "1    juno     742053      5  2019\n",
      "2    uber   15876033      5  2019\n",
      "3     via    1029266      5  2019\n",
      "File fhvhv_tripdata_2019-05.csv has 22329154 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    4999262      6  2019\n",
      "1    juno     674839      6  2019\n",
      "2    uber   14397094      6  2019\n",
      "3     via     930716      6  2019\n",
      "File fhvhv_tripdata_2019-06.csv has 21001911 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    4682351      7  2019\n",
      "1    juno     658012      7  2019\n",
      "2    uber   14043150      7  2019\n",
      "3     via     919798      7  2019\n",
      "File fhvhv_tripdata_2019-07.csv has 20303311 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    4698486      8  2019\n",
      "1    juno     619663      8  2019\n",
      "2    uber   13926305      8  2019\n",
      "3     via     881654      8  2019\n",
      "File fhvhv_tripdata_2019-08.csv has 20126108 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    4611514      9  2019\n",
      "1    juno     625981      9  2019\n",
      "2    uber   13964765      9  2019\n",
      "3     via     866974      9  2019\n",
      "File fhvhv_tripdata_2019-09.csv has 20069234 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    5346314     10  2019\n",
      "1    juno     407494     10  2019\n",
      "2    uber   14509882     10  2019\n",
      "3     via     898587     10  2019\n",
      "File fhvhv_tripdata_2019-10.csv has 21162277 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    5144737     11  2019\n",
      "1    juno     105879     11  2019\n",
      "2    uber   15610941     11  2019\n",
      "3     via     773951     11  2019\n",
      "File fhvhv_tripdata_2019-11.csv has 21635508 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    5429982     12  2019\n",
      "1    uber   16105602     12  2019\n",
      "2     via     707565     12  2019\n",
      "File fhvhv_tripdata_2019-12.csv has 22243149 rows\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2020 data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "fhv2019_count = []\n",
    "month = 1\n",
    "year = 2020\n",
    "for file in sorted(os.listdir(os.path.join(data_dir,\"Trip\",\"fhvhv\", \"2020\"))):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_dir,\"Trip\",\"fhvhv\", \"2020\", file)\n",
    "        fhv2019 = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(file_path) \n",
    "        fhv2019 = fhv2019.filter(fhv2019.dispatching_base_num.isin(base_numbers)) \\\n",
    "        .withColumn(\"Company\", udfconvert_license_to_company(fhv2019.hvfhs_license_num))\n",
    "\n",
    "        fhv2019.createOrReplaceTempView(\"fhv2019\")\n",
    "        SQL = \"\"\"\n",
    "        SELECT Company, COUNT(*) AS Frequency\n",
    "        FROM fhv2019\n",
    "        GROUP BY Company\n",
    "        \"\"\"\n",
    "        output = spark.sql(SQL).toPandas()\n",
    "        output[\"Month\"] = [month] * len(output.index)\n",
    "        output[\"Year\"] = [year] * len(output.index)\n",
    "        print(output)\n",
    "        output.to_pickle(os.path.join(resource_save, \"Company\",f\"{month}-{year}.pkl\" ))\n",
    "         \n",
    "\n",
    "        count = fhv2019.count()\n",
    "        print(f\"File {file} has {count} rows\")\n",
    "        fhv2019_count.append(count)\n",
    "        month += 1\n",
    "pd.DataFrame(fhv2019_count).to_pickle(os.path.join(resource_save, \"fhv2020.pkl\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Company  Frequency  Month  Year\n",
      "0    lyft    5272933      1  2020\n",
      "1    uber   14582477      1  2020\n",
      "2     via     712600      1  2020\n",
      "File fhvhv_tripdata_2020-01.csv has 20568010 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    5335932      2  2020\n",
      "1    uber   15743375      2  2020\n",
      "2     via     641941      2  2020\n",
      "File fhvhv_tripdata_2020-02.csv has 21721248 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3216493      3  2020\n",
      "1    uber    9836763      3  2020\n",
      "2     via     336606      3  2020\n",
      "File fhvhv_tripdata_2020-03.csv has 13389862 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    1142917      4  2020\n",
      "1    uber    3102835      4  2020\n",
      "2     via      65991      4  2020\n",
      "File fhvhv_tripdata_2020-04.csv has 4311743 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    1619967      5  2020\n",
      "1    uber    4359273      5  2020\n",
      "2     via     109127      5  2020\n",
      "File fhvhv_tripdata_2020-05.csv has 6088367 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    2307960      6  2020\n",
      "1    uber    5110461      6  2020\n",
      "2     via     130025      6  2020\n",
      "File fhvhv_tripdata_2020-06.csv has 7548446 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    2711271      7  2020\n",
      "1    uber    7074343      7  2020\n",
      "2     via     160833      7  2020\n",
      "File fhvhv_tripdata_2020-07.csv has 9946447 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3067042      8  2020\n",
      "1    uber    7845602      8  2020\n",
      "2     via     167678      8  2020\n",
      "File fhvhv_tripdata_2020-08.csv has 11080322 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3111788      9  2020\n",
      "1    uber    8834016      9  2020\n",
      "2     via     142008      9  2020\n",
      "File fhvhv_tripdata_2020-09.csv has 12087812 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3317004     10  2020\n",
      "1    uber    9780191     10  2020\n",
      "2     via     147554     10  2020\n",
      "File fhvhv_tripdata_2020-10.csv has 13244749 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3086229     11  2020\n",
      "1    uber    8363036     11  2020\n",
      "2     via     130898     11  2020\n",
      "File fhvhv_tripdata_2020-11.csv has 11580163 rows\n",
      "  Company  Frequency  Month  Year\n",
      "0    lyft    3018992     12  2020\n",
      "1    uber    8479682     12  2020\n",
      "2     via     127295     12  2020\n",
      "File fhvhv_tripdata_2020-12.csv has 11625969 rows\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "fhv2019 = fhv2019.withColumn(\"month\", month(fhv2019.pickup_datetime)) \\\n",
    "    .withColumn(\"pickup_datetime\", to_timestamp(fhv2019.pickup_datetime, 'yyyy-MM-dd HH:mm:ss') ) \\\n",
    ".withColumn(\"dropoff_datetime\", to_timestamp(fhv2019.dropoff_datetime, 'yyyy-MM-dd HH:mm:ss') ) \n",
    ".withColumn(\"year\", year(fhv2019.pickup_datetime)) \\\n",
    ".withColumn(\"Company\", udfconvert_base_to_company(fhv2019.dispatching_base_num)) \\\n",
    ".withColumn(\"duration\", round((fhv2019.dropoff_datetime.cast(\"long\")  - fhv2019.pickup_datetime.cast(\"long\"))/60)) \\\n",
    ".drop(\"SR_Flag\",'Dispatching_base_number', \"Dispatching_base_num\", \"DropOff_datetime\",\"Pickup_DateTime\"  ) \n",
    "fhv2019.createOrReplaceTempView(\"fhv2019\")\n",
    "fhv2019.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------+------------+-----+----+-------+--------+\n",
      "|PULocationID|DOLocationID|month|year|Company|duration|\n",
      "+------------+------------+-----+----+-------+--------+\n",
      "|          90|          48|    1|2019|   uber|    33.0|\n",
      "|          48|         144|    1|2019|   uber|    26.0|\n",
      "|          48|         144|    1|2019|   uber|    25.0|\n",
      "|         112|         112|    1|2019|   uber|     7.0|\n",
      "|         112|         145|    1|2019|   uber|    10.0|\n",
      "|         145|         225|    1|2019|   uber|    23.0|\n",
      "|         181|          54|    1|2019|   uber|    14.0|\n",
      "|         181|         181|    1|2019|   uber|     4.0|\n",
      "|          18|          78|    1|2019|   uber|    14.0|\n",
      "|         127|         244|    1|2019|   uber|     9.0|\n",
      "|         243|         243|    1|2019|   uber|     7.0|\n",
      "|         144|          79|    1|2019|   uber|     8.0|\n",
      "|         224|         263|    1|2019|   uber|    19.0|\n",
      "|         263|          41|    1|2019|   uber|    11.0|\n",
      "|         239|         265|    1|2019|   uber|    20.0|\n",
      "|         210|         210|    1|2019|   uber|     3.0|\n",
      "|         147|         126|    1|2019|   uber|     5.0|\n",
      "|         126|         168|    1|2019|   uber|     5.0|\n",
      "|         147|          42|    1|2019|   uber|    13.0|\n",
      "|         168|         119|    1|2019|   uber|    16.0|\n",
      "+------------+------------+-----+----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Green data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "green_count = []\n",
    "for file in sorted(os.listdir(os.path.join(data_dir,\"Trip\",\"green\"))):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_dir,\"Trip\",\"green\", file)\n",
    "        fhv2019 = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(file_path)\n",
    "        count = fhv2019.count()\n",
    "        green_count.append(count)\n",
    "        print(f\"File {file} has {count} rows\")\n",
    "pd.DataFrame(green_count).to_pickle(os.path.join(resource_save, \"green.pkl\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File green_tripdata_2018-01.csv has 793529 rows\n",
      "File green_tripdata_2018-02.csv has 769940 rows\n",
      "File green_tripdata_2018-03.csv has 837149 rows\n",
      "File green_tripdata_2018-04.csv has 800084 rows\n",
      "File green_tripdata_2018-05.csv has 797233 rows\n",
      "File green_tripdata_2018-06.csv has 739373 rows\n",
      "File green_tripdata_2018-07.csv has 684455 rows\n",
      "File green_tripdata_2018-08.csv has 666376 rows\n",
      "File green_tripdata_2018-09.csv has 666708 rows\n",
      "File green_tripdata_2018-10.csv has 710510 rows\n",
      "File green_tripdata_2018-11.csv has 656573 rows\n",
      "File green_tripdata_2018-12.csv has 685373 rows\n",
      "File green_tripdata_2019-01.csv has 630918 rows\n",
      "File green_tripdata_2019-02.csv has 575685 rows\n",
      "File green_tripdata_2019-03.csv has 601102 rows\n",
      "File green_tripdata_2019-04.csv has 514392 rows\n",
      "File green_tripdata_2019-05.csv has 504887 rows\n",
      "File green_tripdata_2019-06.csv has 471052 rows\n",
      "File green_tripdata_2019-07.csv has 470743 rows\n",
      "File green_tripdata_2019-08.csv has 449695 rows\n",
      "File green_tripdata_2019-09.csv has 449063 rows\n",
      "File green_tripdata_2019-10.csv has 476386 rows\n",
      "File green_tripdata_2019-11.csv has 449500 rows\n",
      "File green_tripdata_2019-12.csv has 450627 rows\n",
      "File green_tripdata_2020-01.csv has 447770 rows\n",
      "File green_tripdata_2020-02.csv has 398632 rows\n",
      "File green_tripdata_2020-03.csv has 223406 rows\n",
      "File green_tripdata_2020-04.csv has 35612 rows\n",
      "File green_tripdata_2020-05.csv has 57360 rows\n",
      "File green_tripdata_2020-06.csv has 63109 rows\n",
      "File green_tripdata_2020-07.csv has 72257 rows\n",
      "File green_tripdata_2020-08.csv has 81063 rows\n",
      "File green_tripdata_2020-09.csv has 87987 rows\n",
      "File green_tripdata_2020-10.csv has 95120 rows\n",
      "File green_tripdata_2020-11.csv has 88605 rows\n",
      "File green_tripdata_2020-12.csv has 83130 rows\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Yellow data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "green_count = []\n",
    "for file in sorted(os.listdir(os.path.join(data_dir,\"Trip\",\"yellow\", \"2018\"))):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_dir,\"Trip\",\"yellow\", \"2018\", file)\n",
    "        fhv2019 = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(file_path)\n",
    "        count = fhv2019.count()\n",
    "        green_count.append(count)\n",
    "        print(f\"File {file} has {count} rows\")\n",
    "pd.DataFrame(green_count).to_pickle(os.path.join(resource_save, \"yellow2018.pkl\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File yellow_tripdata_2018-01.csv has 8759874 rows\n",
      "File yellow_tripdata_2018-02.csv has 8492076 rows\n",
      "File yellow_tripdata_2018-03.csv has 9430376 rows\n",
      "File yellow_tripdata_2018-04.csv has 9305515 rows\n",
      "File yellow_tripdata_2018-05.csv has 9224063 rows\n",
      "File yellow_tripdata_2018-06.csv has 8713831 rows\n",
      "File yellow_tripdata_2018-07.csv has 7849748 rows\n",
      "File yellow_tripdata_2018-08.csv has 7849134 rows\n",
      "File yellow_tripdata_2018-09.csv has 8040133 rows\n",
      "File yellow_tripdata_2018-10.csv has 8821105 rows\n",
      "File yellow_tripdata_2018-11.csv has 8145164 rows\n",
      "File yellow_tripdata_2018-12.csv has 8173231 rows\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "green_count = []\n",
    "for file in sorted(os.listdir(os.path.join(data_dir,\"Trip\",\"yellow\", \"2019\"))):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_dir,\"Trip\",\"yellow\", \"2019\", file)\n",
    "        fhv2019 = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(file_path)\n",
    "        count = fhv2019.count()\n",
    "        green_count.append(count)\n",
    "        print(f\"File {file} has {count} rows\")\n",
    "pd.DataFrame(green_count).to_pickle(os.path.join(resource_save, \"yellow2019.pkl\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File yellow_tripdata_2019-01.csv has 7667792 rows\n",
      "File yellow_tripdata_2019-02.csv has 7019375 rows\n",
      "File yellow_tripdata_2019-03.csv has 7832545 rows\n",
      "File yellow_tripdata_2019-04.csv has 7433139 rows\n",
      "File yellow_tripdata_2019-05.csv has 7565261 rows\n",
      "File yellow_tripdata_2019-06.csv has 6941024 rows\n",
      "File yellow_tripdata_2019-07.csv has 6310419 rows\n",
      "File yellow_tripdata_2019-08.csv has 6073357 rows\n",
      "File yellow_tripdata_2019-09.csv has 6567788 rows\n",
      "File yellow_tripdata_2019-10.csv has 7213891 rows\n",
      "File yellow_tripdata_2019-11.csv has 6878111 rows\n",
      "File yellow_tripdata_2019-12.csv has 6896317 rows\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "green_count = []\n",
    "for file in sorted(os.listdir(os.path.join(data_dir,\"Trip\",\"yellow\", \"2020\"))):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_dir,\"Trip\",\"yellow\", \"2020\", file)\n",
    "        fhv2019 = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(file_path)\n",
    "        count = fhv2019.count()\n",
    "        green_count.append(count)\n",
    "        print(f\"File {file} has {count} rows\")\n",
    "pd.DataFrame(green_count).to_pickle(os.path.join(resource_save, \"yellow2020.pkl\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File yellow_tripdata_2020-01.csv has 6405008 rows\n",
      "File yellow_tripdata_2020-02.csv has 6299354 rows\n",
      "File yellow_tripdata_2020-03.csv has 3007292 rows\n",
      "File yellow_tripdata_2020-04.csv has 237993 rows\n",
      "File yellow_tripdata_2020-05.csv has 348371 rows\n",
      "File yellow_tripdata_2020-06.csv has 549760 rows\n",
      "File yellow_tripdata_2020-07.csv has 800412 rows\n",
      "File yellow_tripdata_2020-08.csv has 1007284 rows\n",
      "File yellow_tripdata_2020-09.csv has 1341012 rows\n",
      "File yellow_tripdata_2020-10.csv has 1681131 rows\n",
      "File yellow_tripdata_2020-11.csv has 1508985 rows\n",
      "File yellow_tripdata_2020-12.csv has 1461897 rows\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('mast30024asm1': conda)"
  },
  "interpreter": {
   "hash": "3ee96da6bb92bbf5b9d339a3dfb1419b22df50abca65b46f31ce3f2043457e99"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}