{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "root_folder = \"/home/trungdc/unimelb/MAST30024/asm/project 1/\"\n",
    "data_dir = os.path.join(root_folder, \"Data/Weather\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load dataset from JSON to CSV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def process_monthly_json(JSON_Object : json):\n",
    "    \"\"\"\n",
    "    Process monthly json object and store into list of dictionaries    \n",
    "    \"\"\"\n",
    "    output = []\n",
    "    # JSON_Object = json.loads(JSON_Object)\n",
    "    for station in JSON_Object.keys():\n",
    "        for day in JSON_Object[station]:\n",
    "            day[\"station\"] = station\n",
    "        output += JSON_Object[station]\n",
    "\n",
    "    return output\n",
    "\n",
    "with open(os.path.join(data_dir, \"01-2018 to 01-2019.txt\")) as infile:\n",
    "    s = infile.read()\n",
    "    s = s.replace(\"\\'\", \"\\\"\")\n",
    "    processed  = re.split(\"}{\", s)\n",
    "\n",
    "    df = []\n",
    "    count = 1\n",
    "    for month in processed:\n",
    "        if count == 1:\n",
    "            month += \"}\"\n",
    "        elif count == 24:\n",
    "            month = \"{\" + month\n",
    "        else:\n",
    "            month = \"{\" + month + \"}\"\n",
    "        count += 1\n",
    "        monthly_data = process_monthly_json(json.loads(month))\n",
    "        df.extend(monthly_data)\n",
    "    pd.DataFrame(df).to_csv(os.path.join(data_dir, \"Weather.csv\" ))\n",
    "infile.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter irrelevant weather station & Detecting nan value in columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, \"Weather processed.csv\" ))\n",
    "print(\"All station in NY\")\n",
    "df[\"station\"].unique()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All station in NY\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Bridgeport Area', 'Islip Area', 'NY-LaGuardia AP Area',\n",
       "       'NY-Kennedy AP Area', 'NY-Central Park Area', 'Newark Area',\n",
       "       'Caldwell, NJ', 'Canoe Brook, NJ', 'Charlotteburg, NJ',\n",
       "       'Harrison, NJ', 'Newark Airport, NJ', 'Teterboro, NJ',\n",
       "       'Wanaque, NJ', 'Baiting Hollow, NY', 'Bridgehampton, NY',\n",
       "       'Centerport, NY', 'Farmingdale, NY', 'Islip, NY',\n",
       "       'Molly CERCOM, NY', 'Montauk, NY', 'Montgomery, NY',\n",
       "       'Mount Sinai, NY', 'NY Central Park, NY', 'New York JFK, NY',\n",
       "       'New York LGA, NY', 'Orient Point, NY', 'Port Jervis, NY',\n",
       "       'Riverhead, NY', 'Shirley, NY', 'Shrub Oak, NY', 'Syosset, NY',\n",
       "       'Upton/WFO OKX, NY', 'Westhampton, NY', 'West Point, NY',\n",
       "       'White Plains, NY', 'Ansonia 1 NE, CT', 'Bridgeport Arpt, CT',\n",
       "       'Bridgeport Co-op, CT', 'Danbury Arpt, CT', 'Danbury Co-op, CT',\n",
       "       'Groton Arpt, CT', 'Groton Co-op, CT', 'Guilford, CT',\n",
       "       'Meriden Arpt, CT', 'Mount Carmel, CT', 'New Haven, CT',\n",
       "       'Norwich Pub Util, CT', 'Putnam Lake, CT', 'Stamford 5 N, CT',\n",
       "       'Carmel 4N, NY'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "chosen_station = [\"NY-Kennedy AP Area\", \"NY-LaGuardia AP Area\", \"Newark Area\", \"Teterboro, NJ\",\"NY-Central Park Area\", \"New York JFK, NY\"]\n",
    "boolean_series = df.station.isin(chosen_station)\n",
    "filter_df = df[boolean_series]\n",
    "filter_df.drop_duplicates()\n",
    "filter_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Unnamed: 0        date tempMax tempMin tempAvg tempDeparture hdd cdd  \\\n",
       "62          62  2018-01-01      19       8    13.5         -22.6  51   0   \n",
       "63          63  2018-01-02      26      14    20.0         -15.9  45   0   \n",
       "64          64  2018-01-03      30      17    23.5         -12.2  41   0   \n",
       "65          65  2018-01-04      29      20    24.5         -11.0  40   0   \n",
       "66          66  2018-01-05      20      10    15.0         -20.4  50   0   \n",
       "\n",
       "   precipitation newSnow snowDepth               station  \n",
       "62          0.00     0.0         0  NY-LaGuardia AP Area  \n",
       "63          0.00     0.0         0  NY-LaGuardia AP Area  \n",
       "64          0.00     0.0         0  NY-LaGuardia AP Area  \n",
       "65          0.51     7.4         1  NY-LaGuardia AP Area  \n",
       "66          0.00     0.0         7  NY-LaGuardia AP Area  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tempMax</th>\n",
       "      <th>tempMin</th>\n",
       "      <th>tempAvg</th>\n",
       "      <th>tempDeparture</th>\n",
       "      <th>hdd</th>\n",
       "      <th>cdd</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>newSnow</th>\n",
       "      <th>snowDepth</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-22.6</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NY-LaGuardia AP Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-15.9</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NY-LaGuardia AP Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>23.5</td>\n",
       "      <td>-12.2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NY-LaGuardia AP Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>24.5</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1</td>\n",
       "      <td>NY-LaGuardia AP Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-20.4</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NY-LaGuardia AP Area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "for column in ['tempMax', 'tempMin', 'tempAvg', 'tempDeparture', 'hdd', 'cdd', 'precipitation', 'newSnow', 'snowDepth']:\n",
    "   unique_values = filter_df[column].unique()\n",
    "   print(f\"Nonstring value in column {column}\")\n",
    "   for unique_value in unique_values:\n",
    "      try:\n",
    "         float(unique_value)\n",
    "      except ValueError:\n",
    "         print(unique_value)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Nonstring value in column tempMax\n",
      "M\n",
      "Nonstring value in column tempMin\n",
      "M\n",
      "Nonstring value in column tempAvg\n",
      "M\n",
      "Nonstring value in column tempDeparture\n",
      "M\n",
      "Nonstring value in column hdd\n",
      "M\n",
      "Nonstring value in column cdd\n",
      "M\n",
      "Nonstring value in column precipitation\n",
      "T\n",
      "M\n",
      "Nonstring value in column newSnow\n",
      "T\n",
      "M\n",
      "Nonstring value in column snowDepth\n",
      "T\n",
      "M\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, \"Weather processed.csv\" ), na_values = ['NaN','M', 'T', 'nan'])\n",
    "chosen_station = [\"NY-Kennedy AP Area\", \"NY-LaGuardia AP Area\", \"Newark Area\", \"Teterboro, NJ\",\"NY-Central Park Area\", \"New York JFK, NY\"]\n",
    "boolean_series = df.station.isin(chosen_station)\n",
    "filter_df = df[boolean_series] # remove irrelevant station\n",
    "filter_df.drop_duplicates() # remove duplicates row\n",
    "# convert column into float\n",
    "for column in ['tempMax', 'tempMin', 'tempAvg', 'tempDeparture', 'hdd', 'cdd', 'precipitation', 'newSnow', 'snowDepth']:\n",
    "    filter_df[column] = filter_df[column].astype(\"float\") \n",
    "filter_df[\"date\"] = filter_df[\"date\"].astype('datetime64[ns]')\n",
    "filter_df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/trungdc/anaconda3/envs/mast30024asm1/lib/python3.7/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Unnamed: 0       date  tempMax  tempMin  tempAvg  tempDeparture   hdd  \\\n",
       "62          62 2018-01-01     19.0      8.0     13.5          -22.6  51.0   \n",
       "63          63 2018-01-02     26.0     14.0     20.0          -15.9  45.0   \n",
       "64          64 2018-01-03     30.0     17.0     23.5          -12.2  41.0   \n",
       "65          65 2018-01-04     29.0     20.0     24.5          -11.0  40.0   \n",
       "66          66 2018-01-05     20.0     10.0     15.0          -20.4  50.0   \n",
       "\n",
       "    cdd  precipitation  newSnow  snowDepth               station  \n",
       "62  0.0           0.00      0.0        0.0  NY-LaGuardia AP Area  \n",
       "63  0.0           0.00      0.0        0.0  NY-LaGuardia AP Area  \n",
       "64  0.0           0.00      0.0        0.0  NY-LaGuardia AP Area  \n",
       "65  0.0           0.51      7.4        1.0  NY-LaGuardia AP Area  \n",
       "66  0.0           0.00      0.0        7.0  NY-LaGuardia AP Area  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tempMax</th>\n",
       "      <th>tempMin</th>\n",
       "      <th>tempAvg</th>\n",
       "      <th>tempDeparture</th>\n",
       "      <th>hdd</th>\n",
       "      <th>cdd</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>newSnow</th>\n",
       "      <th>snowDepth</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-22.6</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NY-LaGuardia AP Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-15.9</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NY-LaGuardia AP Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>-12.2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NY-LaGuardia AP Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY-LaGuardia AP Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-20.4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NY-LaGuardia AP Area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Further preprocessing & Simple EDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "total_day = len(filter_df[\"date\"].unique())\n",
    "for station in chosen_station:\n",
    "    print(f\"{station} station has {len(filter_df[filter_df.station == station])}/ {total_day} days\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NY-Kennedy AP Area station has 730/ 730 days\n",
      "NY-LaGuardia AP Area station has 730/ 730 days\n",
      "Newark Area station has 700/ 730 days\n",
      "Teterboro, NJ station has 700/ 730 days\n",
      "NY-Central Park Area station has 700/ 730 days\n",
      "New York JFK, NY station has 700/ 730 days\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "for column in filter_df.columns:\n",
    "       print(f\"Column {column} has {filter_df[column].isnull().sum()} null value\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Column Unnamed: 0 has 0 null value\n",
      "Column date has 0 null value\n",
      "Column tempMax has 4 null value\n",
      "Column tempMin has 5 null value\n",
      "Column tempAvg has 5 null value\n",
      "Column tempDeparture has 5 null value\n",
      "Column hdd has 5 null value\n",
      "Column cdd has 5 null value\n",
      "Column precipitation has 615 null value\n",
      "Column newSnow has 826 null value\n",
      "Column snowDepth has 764 null value\n",
      "Column station has 0 null value\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "extracted_output = []\n",
    "for date in filter_df[\"date\"].unique():\n",
    "    filter_by_date = filter_df[filter_df.date == date][['tempMax', 'tempMin', 'tempAvg', 'tempDeparture',\n",
    "      'hdd', 'cdd', 'precipitation', 'newSnow', 'snowDepth']]\n",
    "    row_output = filter_by_date.mean(skipna=True)\n",
    "    row_output[\"date\"] = date\n",
    "    extracted_output.append(row_output)\n",
    "extracted_output = pd.DataFrame(extracted_output)\n",
    "\n",
    "extracted_output.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     tempMax    tempMin    tempAvg  tempDeparture        hdd  cdd  \\\n",
       "0  19.000000   6.833333  12.916667     -21.900000  51.833333  0.0   \n",
       "1  26.666667  12.833333  19.750000     -14.866667  44.833333  0.0   \n",
       "2  29.333333  12.500000  20.916667     -13.500000  44.000000  0.0   \n",
       "3  29.000000  19.000000  24.000000     -10.250000  40.833333  0.0   \n",
       "4  19.000000   9.166667  14.083333     -20.033333  50.833333  0.0   \n",
       "\n",
       "   precipitation  newSnow  snowDepth       date  \n",
       "0       0.000000     0.00        0.0 2018-01-01  \n",
       "1       0.000000     0.00        0.0 2018-01-02  \n",
       "2       0.000000     0.00        0.0 2018-01-03  \n",
       "3       0.591667     8.32        1.0 2018-01-04  \n",
       "4       0.066667     0.00        7.4 2018-01-05  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tempMax</th>\n",
       "      <th>tempMin</th>\n",
       "      <th>tempAvg</th>\n",
       "      <th>tempDeparture</th>\n",
       "      <th>hdd</th>\n",
       "      <th>cdd</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>newSnow</th>\n",
       "      <th>snowDepth</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>12.916667</td>\n",
       "      <td>-21.900000</td>\n",
       "      <td>51.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.666667</td>\n",
       "      <td>12.833333</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>-14.866667</td>\n",
       "      <td>44.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.333333</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>20.916667</td>\n",
       "      <td>-13.500000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>-10.250000</td>\n",
       "      <td>40.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>8.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>9.166667</td>\n",
       "      <td>14.083333</td>\n",
       "      <td>-20.033333</td>\n",
       "      <td>50.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2018-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extracted Output storing NYC data still have na value\n",
    "## Impute each value with value on previous and following day"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "\n",
    "for column in extracted_output.columns:\n",
    "       print(f\"Column {column} has {extracted_output[column].isnull().sum()} null value\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Column tempMax has 0 null value\n",
      "Column tempMin has 0 null value\n",
      "Column tempAvg has 0 null value\n",
      "Column tempDeparture has 0 null value\n",
      "Column hdd has 0 null value\n",
      "Column cdd has 0 null value\n",
      "Column precipitation has 13 null value\n",
      "Column newSnow has 5 null value\n",
      "Column snowDepth has 1 null value\n",
      "Column date has 0 null value\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "for column in extracted_output.columns:\n",
    "    for index, value in extracted_output[column].iteritems():\n",
    "        if pd.isna(value):\n",
    "            print(extracted_output.iloc[[index]])\n",
    "            curdate = extracted_output.iloc[[index]][\"date\"].values[0]\n",
    "            nextdate = curdate + np.timedelta64(1, 'D')\n",
    "            predate = curdate - np.timedelta64(1, 'D')\n",
    "            prevalue = extracted_output[extracted_output.date == predate][column].values[0]\n",
    "            postvalue = extracted_output[extracted_output.date == nextdate][column].values[0]\n",
    "            extracted_output.at[index, column] = (prevalue +postvalue)/2        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      tempMax  tempMin    tempAvg  tempDeparture   hdd  cdd  precipitation  \\\n",
      "28  44.833333     34.0  39.416667       6.566667  25.5  0.0            NaN   \n",
      "\n",
      "    newSnow  snowDepth       date  \n",
      "28      0.1        0.0 2018-01-29  \n",
      "      tempMax    tempMin    tempAvg  tempDeparture        hdd  cdd  \\\n",
      "64  45.833333  30.833333  38.333333      -1.016667  26.333333  0.0   \n",
      "\n",
      "    precipitation  newSnow  snowDepth       date  \n",
      "64            NaN      0.0        0.0 2018-03-06  \n",
      "     tempMax    tempMin    tempAvg  tempDeparture  hdd       cdd  \\\n",
      "124     76.0  59.333333  67.666667       8.466667  0.0  2.833333   \n",
      "\n",
      "     precipitation  newSnow  snowDepth       date  \n",
      "124            NaN      0.0        0.0 2018-05-05  \n",
      "     tempMax  tempMin  tempAvg  tempDeparture  hdd   cdd  precipitation  \\\n",
      "164     85.5     69.0    77.25           5.75  0.0  12.5            NaN   \n",
      "\n",
      "     newSnow  snowDepth       date  \n",
      "164      0.0        0.0 2018-06-14  \n",
      "     tempMax  tempMin  tempAvg  tempDeparture  hdd  cdd  precipitation  \\\n",
      "173     67.0     62.5    64.75          -9.55  0.0  0.0            NaN   \n",
      "\n",
      "     newSnow  snowDepth       date  \n",
      "173      0.0        0.0 2018-06-23  \n",
      "       tempMax    tempMin  tempAvg  tempDeparture  hdd       cdd  \\\n",
      "249  76.833333  70.166667     73.5            1.4  0.0  8.666667   \n",
      "\n",
      "     precipitation  newSnow  snowDepth       date  \n",
      "249            NaN      0.0        0.0 2018-09-07  \n",
      "       tempMax  tempMin    tempAvg  tempDeparture       hdd  cdd  \\\n",
      "295  64.833333     46.5  55.666667       0.483333  9.333333  0.0   \n",
      "\n",
      "     precipitation  newSnow  snowDepth       date  \n",
      "295            NaN      0.0        0.0 2018-10-23  \n",
      "       tempMax    tempMin    tempAvg  tempDeparture        hdd  cdd  \\\n",
      "377  33.666667  24.166667  28.916667      -4.133333  35.833333  0.0   \n",
      "\n",
      "     precipitation  newSnow  snowDepth       date  \n",
      "377            NaN      0.1        0.0 2019-01-13  \n",
      "       tempMax  tempMin    tempAvg  tempDeparture        hdd  cdd  \\\n",
      "452  57.666667     46.0  51.833333            5.7  13.166667  0.0   \n",
      "\n",
      "     precipitation  newSnow  snowDepth       date  \n",
      "452            NaN      0.0        0.0 2019-03-29  \n",
      "       tempMax    tempMin  tempAvg  tempDeparture        hdd  cdd  \\\n",
      "470  65.833333  42.666667    54.25            1.4  10.666667  0.0   \n",
      "\n",
      "     precipitation  newSnow  snowDepth       date  \n",
      "470            NaN      0.0        0.0 2019-04-16  \n",
      "     tempMax    tempMin    tempAvg  tempDeparture       hdd  cdd  \\\n",
      "472     62.0  50.333333  56.166667       2.583333  8.333333  0.0   \n",
      "\n",
      "     precipitation  newSnow  snowDepth       date  \n",
      "472            NaN      0.0        0.0 2019-04-18  \n",
      "       tempMax    tempMin    tempAvg  tempDeparture  hdd  cdd  precipitation  \\\n",
      "641  67.166667  49.666667  58.416667      -3.916667  6.5  0.0            NaN   \n",
      "\n",
      "     newSnow  snowDepth       date  \n",
      "641      0.0        0.0 2019-10-04  \n",
      "       tempMax    tempMin    tempAvg  tempDeparture   hdd  cdd  precipitation  \\\n",
      "702  39.666667  31.666667  35.666667           -6.1  29.0  0.0            NaN   \n",
      "\n",
      "     newSnow  snowDepth       date  \n",
      "702      0.0        0.0 2019-12-04  \n",
      "     tempMax  tempMin    tempAvg  tempDeparture        hdd  cdd  \\\n",
      "7  31.666667     17.0  24.333333      -9.333333  40.333333  0.0   \n",
      "\n",
      "   precipitation  newSnow  snowDepth       date  \n",
      "7         0.0575      NaN        6.8 2018-01-08  \n",
      "      tempMax  tempMin    tempAvg  tempDeparture        hdd  cdd  \\\n",
      "32  40.166667     17.0  28.583333      -4.616667  36.166667  0.0   \n",
      "\n",
      "    precipitation  newSnow  snowDepth       date  \n",
      "32          0.175      NaN        0.0 2018-02-02  \n",
      "      tempMax  tempMin    tempAvg  tempDeparture        hdd  cdd  \\\n",
      "60  44.833333     34.5  39.666667       1.316667  25.166667  0.0   \n",
      "\n",
      "    precipitation  newSnow  snowDepth       date  \n",
      "60       1.946667      NaN        0.0 2018-03-02  \n",
      "     tempMax  tempMin  tempAvg  tempDeparture        hdd  cdd  precipitation  \\\n",
      "324     46.0     27.0     36.5          -9.15  28.166667  0.0           0.01   \n",
      "\n",
      "     newSnow  snowDepth       date  \n",
      "324      NaN        0.0 2018-11-21  \n",
      "       tempMax  tempMin    tempAvg  tempDeparture        hdd  cdd  \\\n",
      "408  41.833333     33.0  37.416667           2.65  27.166667  0.0   \n",
      "\n",
      "     precipitation  newSnow  snowDepth       date  \n",
      "408          0.055      NaN        1.0 2019-02-13  \n",
      "     tempMax    tempMin    tempAvg  tempDeparture   hdd  cdd  precipitation  \\\n",
      "423     37.0  26.833333  31.916667          -5.95  33.0  0.0       0.023333   \n",
      "\n",
      "     newSnow  snowDepth       date  \n",
      "423     0.12        NaN 2019-02-28  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## After processing, extracteed output has No Na value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "for column in extracted_output.columns:\n",
    "       print(f\"Column {column} has {extracted_output[column].isnull().sum()} null value\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Column tempMax has 0 null value\n",
      "Column tempMin has 0 null value\n",
      "Column tempAvg has 0 null value\n",
      "Column tempDeparture has 0 null value\n",
      "Column hdd has 0 null value\n",
      "Column cdd has 0 null value\n",
      "Column precipitation has 0 null value\n",
      "Column newSnow has 0 null value\n",
      "Column snowDepth has 0 null value\n",
      "Column date has 0 null value\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "extracted_output.to_csv(os.path.join(data_dir, \"Weather processed.csv\"))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('mast30024asm1': conda)"
  },
  "interpreter": {
   "hash": "3ee96da6bb92bbf5b9d339a3dfb1419b22df50abca65b46f31ce3f2043457e99"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}